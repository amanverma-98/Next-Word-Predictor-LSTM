{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MMCyqTqJq-8c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import random\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOrvVrZZpKNV",
        "outputId": "2bd49016-5d68-4cfe-bfb2-a5e420b5f29c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total questions: 150000\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/train.csv\" , engine=\"python\", on_bad_lines=\"skip\", nrows=200_000)\n",
        "\n",
        "questions = []\n",
        "for q1, q2 in zip(df[\"question1\"], df[\"question2\"]):\n",
        "    if isinstance(q1, str):\n",
        "        questions.append(q1.lower())\n",
        "    if isinstance(q2, str):\n",
        "        questions.append(q2.lower())\n",
        "\n",
        "# LIMIT DATA\n",
        "questions = questions[:150_000]\n",
        "\n",
        "print(\"Total questions:\", len(questions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HS9F-agKqrO_"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE = 8000\n",
        "\n",
        "counter = Counter()\n",
        "for q in questions:\n",
        "    counter.update(q.split())\n",
        "\n",
        "vocab = [w for w, _ in counter.most_common(VOCAB_SIZE)]\n",
        "\n",
        "word2idx = {w: i+1 for i, w in enumerate(vocab)}\n",
        "idx2word = {i: w for w, i in word2idx.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yll7yb7PqueU",
        "outputId": "a213d3f6-e86f-4b1a-8f2c-7e0475bbbb85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total tokens: 1456003\n"
          ]
        }
      ],
      "source": [
        "SEQ_LEN = 4\n",
        "\n",
        "tokens = []\n",
        "for q in questions:\n",
        "    words = [word2idx[w] for w in q.split() if w in word2idx]\n",
        "    if len(words) >= SEQ_LEN + 1:\n",
        "        tokens.extend(words)\n",
        "\n",
        "print(\"Total tokens:\", len(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iEZo6SnkqxgS"
      },
      "outputs": [],
      "source": [
        "class WordDataset(Dataset):\n",
        "    def __init__(self, tokens, seq_len):\n",
        "        self.tokens = tokens\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokens) - self.seq_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.tokens[idx:idx+self.seq_len]\n",
        "        y = self.tokens[idx+self.seq_len]\n",
        "        return torch.tensor(x), torch.tensor(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SawQYdsgrQUp"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(\n",
        "    WordDataset(tokens, SEQ_LEN),\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qzPYvQgurUqD"
      },
      "outputs": [],
      "source": [
        "class WordLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size + 1, 128)\n",
        "        self.lstm = nn.LSTM(128, 256, batch_first=True)\n",
        "        self.fc = nn.Linear(256, vocab_size + 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out[:, -1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nW_d2hNFrXoJ"
      },
      "outputs": [],
      "source": [
        "model = WordLSTM(len(word2idx)).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "EPOCHS = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-3I56dIrbw-",
        "outputId": "e4d07d63-25e5-428d-ff59-7edec13c76ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3 | Loss: 4.6446\n",
            "Epoch 2/3 | Loss: 4.2901\n",
            "Epoch 3/3 | Loss: 4.2349\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(model(x), y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {total_loss/len(train_loader):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hCnFCzU9rghr"
      },
      "outputs": [],
      "source": [
        "def autocomplete(prompt, num_words=3, temperature=0.7, top_k=5):\n",
        "    model.eval()\n",
        "    words = prompt.lower().split()\n",
        "\n",
        "    for _ in range(num_words):\n",
        "        seq = [word2idx.get(w, 0) for w in words[-SEQ_LEN:]]\n",
        "        seq = [0]*(SEQ_LEN-len(seq)) + seq\n",
        "\n",
        "        x = torch.tensor(seq).unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(x) / temperature\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            top_probs, top_idx = torch.topk(probs, top_k)\n",
        "\n",
        "            next_word = random.choices(\n",
        "                top_idx[0].tolist(),\n",
        "                weights=top_probs[0].tolist()\n",
        "            )[0]\n",
        "\n",
        "        words.append(idx2word.get(next_word, \"\"))\n",
        "\n",
        "    return \" \".join(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxbjWKMhrjsA",
        "outputId": "200f9a29-ea0e-4a0d-e730-3ff5a2f6b18c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "how to learn how to play\n",
            "what is machine learning programming\n",
            "best way to get a job\n"
          ]
        }
      ],
      "source": [
        "print(autocomplete(\"how to learn\", 3))\n",
        "print(autocomplete(\"what is machine\", 2))\n",
        "print(autocomplete(\"best way to\", 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8niFP12Tt36H"
      },
      "outputs": [],
      "source": [
        "torch.save({\n",
        "    \"model_state\": model.state_dict(),\n",
        "    \"word2idx\": word2idx,\n",
        "    \"idx2word\": idx2word\n",
        "}, \"autocomplete_model.pth\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dlenv (3.12.4)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
